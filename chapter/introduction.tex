\chapter{Introduction}

\section{Motivation}
Both in theory and practice computer scientists encounter computationally hard problems in a large variety of fields. These include e.g. register allocation in compilers, timetable layout and tour planning, all of which are formalised in a graph theoretic \cite{} representation.

The limiting factor in these problems is the huge number of possible solutions, which \textbf{all} have to be examined in order to find the optimal solution \cite{Garey:1979:CIG:578533}. Even for small problem instances the number of possible solutions is so big that this approach is rendered impractical. To tackle this difficulty, usually approximation algorithms \cite{}, distributed algorithms or distributed approximation algorithms are employed. The idea behind distributed algorithms is to apply more processing power to find a solution faster. Approximation algorithms try to find a solution that is good enough to satisfy a defined criterion.

In contrast to \enquote{big data} where there is usually a data volume of several terabytes involved, we will only deal with problem instances of up to a few hundred KB\footnote{Depending on the chosen representation, the size might vary.}. Due to the huge amount of computations to be carried out and to make a distinction against \enquote{big data}, we refer to this as \enquote{big computation}.

Many of the currently widely used programming languages such as Java and Python come with libraries for development of distributed programs. These libraries contain tools for running code remotely, serializing\footnote{In fact, serialisation is usually done implicitly by the runtime system.} data, sending data to remote processes as well as concepts for synchronisation. These tools are exactly we use use to build distributed algorithms. However, unrelated to the particular problem, the code produced in this context always looks very similar and doesn't come with further enlightenment.

A bit more precisely, we are dealing with intractable problems from the class $\mathcal{NPC}$\footnote{$\mathcal{NPO}$ respectively in the case of optimisation problems.} \cite{Garey:1979:CIG:578533}, \cite{Hopcroft:2006:IAT:1196416}. For these problems it takes up a huge amount of time to search the solution space since it is exponential in the size of the problem input. It is widely believed, though not proven, that these problems cannot be solved to optimality in polynomial time. In fact it isn't even known if this property can be formally proven at all \cite{}. Nevertheless many research results suggest that this \enquote{intuition} holds \cite{} \cite{} \cite{}.

\section{Goal}
Our goal is to design a toolbox that allows for development of distributed algorithms on a higher level of abstraction. Ideally we want to be able to take functions, wrap them into processes, compose these processes and run the resulting process in a distributed system. We don't want the user of this toolbox to be concerned about communication between processes, serialisation of data or synchronisation of processes. The fact that the process will be executed in a disctributed system should be hidden entirely.



\section{Results}