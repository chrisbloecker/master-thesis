\nomenclature[500]{\hfill}{}
\nomenclature[501]{$G$\dotfill}{A graph}
\nomenclature[502]{$V$\dotfill}{Set of nodes of a graph}
\nomenclature[503]{$E$\dotfill}{Set of edges of a graph}
\nomenclature[504]{$\delta$\dotfill}{Labelling function for graph edges}
\nomenclature[505]{$\phi$\dotfill}{Function that gives the length of a path in a graph}

\nomenclature[510]{\hfill}{}
\nomenclature[511]{$N\left(i\right)$\dotfill}{Set of unvisited neighbour nodes of node $i$}
\nomenclature[512]{$\eta_{i,j}$\dotfill}{Heuristic value of edge from node $i$ to $j$}
\nomenclature[513]{$\tau_{i,j}$\dotfill}{Pheromone concentration on edge from node $i$ to $j$}
\nomenclature[514]{$\tau_0$\dotfill}{Initial pheromone concentration}
\nomenclature[515]{$\tau^+_i$\dotfill}{Pheromone amount to be deposited by ant $i$ on used edges}
\nomenclature[516]{$\alpha$\dotfill}{Value to weigh the influence of pheromones}
\nomenclature[517]{$\beta$\dotfill}{Value to weigh the influence of heuristic information}
\nomenclature[518]{$p_j$\dotfill}{Probability of visiting node $j$ next}
\nomenclature[519]{$s_i$\dotfill}{Solution candidate $i$}
\nomenclature[520]{$c_s$\dotfill}{Costs of solution $s$}

\nomenclature[950]{TSP\dotfill}{Travelling Salesman Problem}

\chapter{A Real World Example\index{Example}}
\vspace*{-0.5em}
In this chapter, we use the previously developed process calculus to build a distributed program that finds solutions for the travelling salesman problem\index{Travelling Salesman Problem}. Since the travelling salesman problem is considered to be a computationally hard optimisation problem, we do not have extended hopes in finding optimal solutions. This is a common case in practical applications. We apply the meta-heuristic\index{Meta-heuristic} approach of artificial ant systems to find approximate solutions for the travelling salesman problem.

\section{The Travelling Salesman Problem\index{Travelling Salesman Problem}}
\label{chp:tsp}
\vspace*{-0.5em}
The travelling salesman problem (or short: \textsc{TSP}\index{TSP}) is a graph theoretic\index{Graph Theory} optimisation problem. For a graph $G = \left( V, E, \delta \right)$ where $V = \left\{ v_1, v_2, \ldots, v_n \right\}$ is the set of nodes, $E \subseteq V \times V$ is the set of edges, i.e. the connections between the nodes, and $\delta \colon E \to \mathbb{N}$ is a function that assigns a length to every edge. The \textsc{TSP} asks for the \textbf{shortest} round trip through the nodes of $G$.


A round trip\index{Round Trip} is a permutation\index{Permutation} of the nodes of $G$, hence every node appears exactly once in a round trip. The length of a round trip is given by the sum of the lengths of its pieces, which are defined by $\delta$. Let $i = \left( i_1, i_2, \ldots, i_n \right)$ be a permutation of the natural numbers from $[1, n] \subset \mathbb{N}$. $i$ defines a numbering of the nodes of $G$ and represents a permutation of them. Let $r_i = \left( v_{i_1}, v_{i_2}, \ldots v_{i_n} \right)$ be the round trip defined by the indices given by $i$. The length $\phi \left( r_i \right)$ of $r_i$ is implied by $\delta$ and can be calculated by
\vspace*{-0.5em}
\begin{equation*}
  \label{eqn:length_roundtrip}
  \phi \left( r_i \right) = \delta \left( \left( v_{i_n}, v_{i_1} \right) \right) + \sum_{j=1}^{n-1} \delta \left( \left( v_{i_j}, v_{i_{j+1}} \right) \right).
\end{equation*}

\vspace*{-0.5em}
Note that, in order to resemble the cyclic nature of a permutation, the length of the edge from the last node back to the first node must not be forgotten. This is necessary to make the path induced by the permutation a round trip.


The \textsc{TSP} is considered to be a computationally hard optimisation\index{Optimisation Problem} problem and belongs to the class of $\mathcal{NP}$-hard problems \cite{Garey:1979:CIG:578533}. This means that there is no known efficient algorithm\index{Algorithm} that finds the solution to an arbitrary, non-restricted instance of the \textsc{TSP}. Furthermore, it is widely believed that no such algorithm can exist at all. Except for some special cases where there are constraints put on the structure of the graph, the only way to find the optimal solution is to check \textbf{all} possible solutions for optimality. Since for an arbitrary graph the number of possible solutions is exponential in its number of nodes, the approach of exploring \textbf{every} possible solution is impractical even for graphs with reasonably few nodes. For an extended discussion of the \textsc{TSP}, see \cite{shmoys1985traveling}.

A real world application of the \textsc{TSP} is just as the name suggests a scenario where there is a travelling salesman who has to visit a number of houses or cities each exactly once to sell his goods and then return home. It is naturally in his interest to choose the shortest way in order to minimise travelling costs and/or time. Another application is, e.g. the problem of determining the drilling order for holes in mining operations in order to minimise the moving time for the drill.

\section{Meta-heuristics\index{Meta-heuristic}}
\label{chp:meta_heuristics}
Meta-heuristics\footnote{Heuristic, from Greek $E\nu\rho\iota\sigma\kappa\omega$: \enquote{find} or \enquote{discover}.} are an approach to tackle the problem that arises with huge sets of possible solutions, which, like in the case of the \textsc{TSP}, is common in practical applications. The idea of meta-heuristics is to explore the set of possible solutions in a more intelligent way than checking \textbf{every} possible solution for optimality. Meta-heuristics try to make an \enquote{intelligent guess} about which solution might be close to optimal and can be based on different, problem-specific criteria. As a direct consequence of \enquote{intelligent guessing}, it is very well possible to miss the optimal solution.

One thing different meta-heuristics have in common is a solution finding principle called \textbf{local search}\index{Local search}. In \textbf{local search}, first an initial solution candidate\index{Candidate} is generated using a suitable construction algorithm\index{Algorithm}. The meta-heuristic aims to improve this candidate iteratively: based on defined criteria, modifications are made to the solution candidate in the hope of finding a closer to optimal solution. The modifications yield a set of solutions similar to the solution candidate, called its \textbf{local neighbourhood}\index{Neighbourhood}. From the local neighbourhood, the closest to optimal solution is chosen to replace the previous solution candidate \cite{Dorigo:2004:ACO:975277}.

When applying this approach, it might happen that in the local neighbourhood of a solution candidate, there is no closer to optimal solution than the candidate itself. In this case, the candidate is considered to be a so-called \textbf{local optimum}. A local optimum\index{Optimum!Local} might be the global optimum\index{Optimum!Global}, however in general this is highly unlikely. Therefore, if the meta-heuristic runs into such a situation, it must allow to escape local optima and execute steps towards farther from optimal solutions. As a direct consequence, the meta-heuristic must have a way to prevent from directly running back into the same local optimum as this is likely to happen in the step after proceeding towards a farther from optimal solution. A common approach to achieve this is the use of a so-called \textbf{tabu list}\index{Tabu List}: a tabu list keeps track of the most recently visited solutions candidates \cite{Dorigo:2004:ACO:975277}. As long as a candidate is in the tabu list, it must not be chosen again. Unfortunately, this does not entirely eliminate the possibility of running into the same solution again. The solution space might have cycles of higher length than the length of the tabu list, causing the meta-heuristic to return to an undesirable solution.

The term meta-heuristic is chosen because it involves heuristics to guess solutions and is applicable to a wide field of problems. With a meta-heuristic, we have a \enquote{recipe} of how to build a heuristic algorithm to solve arbitrary problems, as long as we can define the local neighbourhood of a solution.

\section{Artificial Ant Systems\index{Ant System}}
\label{chp:ant_system}
Artificial ant systems are a meta-heuristic\index{Meta-heuristic} approach that can be applied to a big variety of computationally hard optimisation problems that can be represented as a graph\index{Graph}, like the \textsc{TSP}. An overview about different types of ant systems and example applications can be found in \cite{Dorigo:2004:ACO:975277}. Here, we only briefly discuss one form of ant systems and use the developed process calculus to implement a prototype\index{Prototype} of an ant system that finds approximate solutions for instances of the \textsc{TSP}\index{TSP}. Without further mentioning, \cite{Dorigo:2004:ACO:975277} serves us as a reference throughout this chapter.

Artificial ant systems are inspired by the swarm behaviour of ants from ant colonies in nature. When in search for new food sources, natural ants explore their environment by performing random walks. Once they discover a new food source, they return to their colony and mark the way to the food source with so called \textit{pheromones}\index{Pheromone}. These pheromones can be sensed by other ants to guide their way to the food source. When an ant encounters a pheromone trail, it makes a decision between following it or continuing exploring its environment randomly. The probability of following a trail gets higher as it gets covered more densely with pheromones. If the ant decides to follow the pheromone trail, it continues up to the food source, picks up some food and carries it back to its colony. On the way back, it reinforces the pheromone trail by depositing additional pheromones. Over time, more and more ants follow the pheromone trail and an ant trail emerges. A natural phenomenon called \textit{evaporation}\index{Evaporation} counters the built-up of trails: a small fraction of pheromones disappears continuously, so the trail vanishes eventually if there are no ants left reinforcing it.

Artificial ant systems resemble the described situation from nature and employ a graph\index{Graph} to do so. Depending on the problem at hand, one node of the graph is selected to represent the ant colony. At this special node, ants are generated to perform an exploration of the graph and construct a solution to the problem represented by the graph. In case of the \textsc{TSP}\index{TSP}, a valid solution is one that represents a permutation of the graph's nodes. An ant starts its round trip\index{Round Trip} through the graph at the colony, selects one of the unvisited nodes and proceeds to it. It continues doing so until it has visited all of the nodes, then it returns to the colony. It does not matter which node is selected to represent the colony since every node has to appear in the solution exactly once.

When constructing a round trip\index{Round Trip} for a graph $G = \left( V, E, \delta \right)$, ants are guided by two different values. On the one hand, they use a heuristic value based on the value of an edge to estimate its desirability: for an edge $\left(i, j\right) \in E$, its heuristic value is given by
\vspace*{-0.5em}
\begin{equation}
  \label{eqn:eta}
  \eta_{i,j} = \frac{1}{\delta \left( \left(i, j \right) \right)}.
\end{equation}

\vspace*{-0.5em}
An edge with a smaller value, i.e. a short edge, has a higher heuristic value than a long edge. For ants, higher heuristic values are desirable, i.e. short edges. On the other hand, pheromone trails $\tau$ are used. The pheromone concentration on the edge from node $i$ to $j$ is denoted by $\tau_{i,j}$. In the beginning, an initial pheromone concentration $\tau_0$ is deposited on every edge of the graph. As the ant system preforms its work, the pheromone values are updated and changed over time.


In each step, an ant picks the next node to visit non-deterministically based on a visiting probability obtained from a combination of heuristic values and pheromone values. Let $N \left( i \right)$ be the set of unvisited neighbour nodes for an ant that is currently at node $i$. The probability of visiting node $j$ is given by
\vspace*{-0.5em}
\begin{equation}
  \label{eqn:probability}
  p_{j} = \frac{\tau_{i,j}^\alpha \eta_{i,j}^\beta}{\sum_{j \in N \left( i \right)} \tau_{i,j}^\alpha \eta_{i,j}^\beta}.
\end{equation}

\vspace*{-0.5em}
where $\alpha$ and $\beta$ are values to weigh the influence of $\tau$ and $\eta$. A random value $r \in \left[0, 1 \right]$ is generated and used to choose a node based on the visiting probabilities. However, to save runtime, the approach from \cite{Bloecker} is applied and only the nominators from \eqnref{eqn:probability} are calculated. Then, instead of generating a random value $r \in \left[0, 1 \right]$, a value $r' \in \left[0, \sum_{j \in N \left( i \right)} p_j \right]$ is generated and used for the selection of a node. The result is left unchanged by this modification.

As a direct consequence of how ants construct their way through the graph, they need a complete graph to operate on, otherwise they might run into situations where they get stuck in one node because there are no more reachable, unvisited nodes left from where they are. Fortunately, every graph can be extended to be a complete graph without altering the optimal solution to the \textsc{TSP}: Let $G = \left( V, E, \delta \right)$ be a graph. For every edge $\overline{e}$ that does not exist in the graph, i.e. $\overline{e} \in \left( V \times V \right) \setminus E$, we introduce a new edge and assign a suitably large value $\delta \left( \overline{e} \right)$ to it, e.g. $\delta \left( \overline{e} \right) = 1 + \sum_{e \in E} \delta \left( e \right)$. We make sure that none of the added edges can possibly be part of an optimal solution by assigning a value to them that is guaranteed to be higher than the value of the optimal solution. For other problems, the process of adapting the graph to a suitable form may look differently.


When all ants have finished the construction of a round trip, each of them deposits new pheromones on all the edges it has used for the construction of its solution. The longer the round trip is, the less desirable it is and hence, the less pheromones should be added by that ant. Let $s_i$ be the solution candidate, i.e. the round trip, that has been constructed by ant $i$ and let $c_{s_i}$ be its costs, induced by $\delta$ and summation over the used edges in $s_i$. Then ant $i$ is allowed to deposit additional pheromones of $\tau_i^+ = \frac{1}{c_{s_i}}$ on every used edge and $\tau_i^+ = 0$ on unused edges. Note that there are various other ways to handle pheromone updates, many of which can be found in \cite{Dorigo:2004:ACO:975277}.

After ants have deposited new pheromones, evaporation takes place on all edges. An evaporation factor $\rho$ specifies which fraction of the pheromones survives evaporation:
\vspace*{-0.5em}
\begin{equation}
  \label{eqn:evaporation}
  \tau_{i,j}' = \left( 1 - \rho \right) \tau_{i,j}.
\end{equation}

\vspace*{-0.5em}

Ant systems perform their work in three phases:
\begin{enumerate}
  \item initialisation \\
    initial pheromones of concentration $\tau_0$ are deposited on all edges of the graph
  \vspace*{-0.5em}
  \item construction \\
    a predefined number of ants is created, each of which constructs a solution candidate \hspace*{-1em}
  \vspace*{-0.5em}
  \item update \\
    ants deposit new pheromones and evaporation takes place
\end{enumerate}
Phase (1) takes place exactly once. The combination of phases (2) and (3) is called a \textit{cycle}\index{Cycle}. Cycles take place repeatedly until either a predefined maximum execution time is reached or a solution of sufficient quality has been found. Other criteria to terminate the computation can be applied as well.

\section{A Prototype of a Distributed Ant System\index{Ant System}\index{Prototype}}
\label{chp:ant_system_implementation}
Having introduced the principles of ant systems, we use our process calculus to implement a distributed ant system. Most notably, we do so without specifying any explicit communication between processes, illustrating that the process calculus fulfils its purpose.

The model for the configuration of the ant system, including the previously mentioned necessary parameters, can be found in \lstref{lst:ant_conf}. The actual problem input is given by \texttt{graph}, \texttt{cycles} specifies how many cycles should be performed by the ant system, \texttt{alpha} and \texttt{beta} are used by the ants when exploring solutions and \texttt{rho} is the evaporation factor. The configuration also includes the current pheromones and the best solution to the problem that has been found so far, both kept up to date by the ant system. Furthermore, it must be possible to send the configuration over the network to ants running on other nodes in a distributed system. Therefore instances for the type classes \texttt{Generic}, \texttt{Typeable} and \texttt{Binary} are included.

\begin{lstlisting}[language=Haskell,frame=tb,numbers=left,label=lst:ant_conf,caption=Imports and configuration for the ant system., basicstyle=\footnotesize\ttfamily]
import Process
import Graph
import Pheromones

type Solution = (Path, Int)

data Configuration = Configuration { graph      :: !(Graph Int)
                                   , pheromones :: !Pheromones
                                   , solution   :: !Solution
                                   , cycles     :: Int
                                   , alpha      :: Double
                                   , beta       :: Double
                                   , rho        :: Double
                                   }
  deriving (Generic, Typeable)

instance Binary Configuration where
\end{lstlisting}

Next, the basic processes which are later wrapped into processes are defined. The basic processes can be found in \lstref{lst:ant_basic}, their implementation details are not shown here, but can be found in \appref{app:ant_system_processes} and \appref{app:dvd}. For now, only the existence of these processes and what they do is important.

\begin{lstlisting}[language=Haskell,frame=tb,numbers=left,label=lst:ant_basic,caption=Signatures of the basic processes for the ant system.,firstnumber=18]
ant             :: Configuration -> CH.Process Solution
combinePaths    :: (Configuration, [Solution])
                -> CH.Process Configuration
evaporations    :: Configuration -> CH.Process Configuration
cycle           :: Configuration -> CH.Process Configuration
continue        :: Configuration -> CH.Process Bool
extractSolution :: Configuration -> CH.Process Solution
\end{lstlisting}

\texttt{ant} represents an ant that is supplied with a configuration and returns a solution candidate for the presented problem.

\texttt{combinePaths} receives a configuration and a list of candidate solutions and returns a new configuration. To do so, it takes list of solution candidates and updates the pheromone concentrations for the graph stored in the configuration and the best known solution so far.

\texttt{evaporations} takes the configuration and updates the pheromone values by reducing the pheromone concentration on every edge according to the evaporation parameter \texttt{rho}.

\texttt{cycle} decreses the value of \texttt{cycles} in the configuration by $1$, signalling that one less cycle should be performed by the ant system.

\texttt{continue} receives a configuration and determines whether the ant system should perform another cycle, depending on the value of \texttt{cycles} in the configuration. If another cycle should be performed, \texttt{continue} returns \texttt{True} and \texttt{False} otherwise.

\texttt{extractSolution} is fairly simple and does not do anything else than extracting the best known solution from the configuration it is supplied with.

As discussed in \chpref{chp:cloud_haskell}, a \texttt{SerializableDict} for every data type that should be sent over the network to another process has to be provided. This is the case for \texttt{Solution}, \texttt{Configuration} and \texttt{Bool} since values of these types are returned by the basic processes. As a brief reminder: a \texttt{SerializableDict} is basically just an explicit type tag and does not involve anything more than using a type constructor, as can be seen in \lstref{lst:ant_dicts}.

\begin{lstlisting}[language=Haskell,frame=tb,numbers=left,label=lst:ant_dicts,caption=Dictionaries for data serialisation.,firstnumber=25]
boolDict :: SerializableDict Bool
boolDict = SerializableDict

solutionDict :: SerializableDict Solution
solutionDict = SerializableDict

configurationDict :: SerializableDict Configuration
configurationDict = SerializableDict
\end{lstlisting}

In order to make the basic \textsf{Cloud Haskell} processes and the dictionaries remotely usable, their names have to be passed to \texttt{remotable}, as shown in \lstref{lst:ant_remotable}. \texttt{remotable} creates the closures for the given functions, their decoders and meta information and adds the information to a table of functions that can be used remotely.

\begin{lstlisting}[language=Haskell,frame=tb,numbers=left,firstnumber=33,label=lst:ant_remotable,caption=Making processes and dictionaries remotable.]
remotable [ 'ant
          , 'combinePaths
          , 'evaporations
          , 'cycle
          , 'continue
          , 'extractSolution
          , 'boolDict
          , 'solutionDict
          , 'configurationDict
          ]
\end{lstlisting}

Next, the basic processes can be wrapped into processes using the \texttt{Basic} constructor. For that, \textsf{Template Haskell} is used to generate the necessary dictionaries for serialisation and the function closures. As modelled in \chpref{chp:distributed_model}, the input and output type of the respective basic process determine the signature of the resulting process and the type of the necessary \texttt{SerliazableDict}. The processes are shown in \lstref{lst:ant_hive}.

\begin{lstlisting}[language=Haskell,frame=tb,numbers=left,firstnumber=43,label=lst:ant_hive,caption={Processes, built up from previously defined basic processes.}, basicstyle=\footnotesize\ttfamily]
antP :: Process Configuration Solution
antP = Basic $(mkStatic  'solutionDict) 
             $(mkClosure 'ant)

combinePathsP :: Process (Configuration, [Solution]) Configuration
combinePathsP = Basic $(mkStatic  'configurationDict)
                      $(mkClosure 'combinePaths)

evaporationP :: Process Configuration Configuration
evaporationP = Basic $(mkStatic  'configurationDict)
                     $(mkClosure 'evaporations)

cycleP :: Process Configuration Configuration
cycleP = Basic $(mkStatic  'configurationDict)
               $(mkClosure 'cycle)

continueP :: Predicate Configuration
continueP = Basic $(mkStatic  'boolDict)
                  $(mkClosure 'continue)

extractSolutionP :: Process Configuration Solution
extractSolutionP = Basic $(mkStatic  'solutionDict)
                         $(mkClosure 'extractSolution)
\end{lstlisting}

Now, all the necessary pieces to put together an ant system are prepared: the processes (\lstref{lst:ant_hive}), the data model (\lstref{lst:ant_conf}) and the process combinators from the developed process calculus. The function \texttt{mkAntSystem} takes an integer that defines how many ants should be used in the ant system and returns a processes that, when executed using the process interpreter \texttt{runProcess}, behaves like an ant system.

\begin{lstlisting}[language=Haskell,frame=tb,numbers=left,firstnumber=66,label=lst:ant_system_complete,caption=Transformation of a configuration for an ant system into a process hierarchy., basicstyle=\footnotesize\ttfamily]
mkAntSystem :: Int -> Process Configuration Solution
mkAntSystem ants =
  let antsP   = Multilel (replicate ants antP) (Local combinePathsP)
      innerP  = antsP `Sequence` Local (evaporationP `Sequence` cycleP)
      cyclesP = Repetition continueP innerP
  in cyclesP `Sequence` Local extractSolutionP
\end{lstlisting}

The ant system constructed by \texttt{mkAntSystem} consists of a sequential composition of all the cycles that have to be executed, namely \texttt{cyclesP}, and a process that extracts the solution in the end, namely \texttt{extractSolutionP}. \texttt{cyclesP} is created using the \texttt{Repetition} constructor and is guarded by the \texttt{continueP} predicate. As long as there are cycles left that should be executed, the process \texttt{innerP} is executed. \texttt{innerP} is the sequential composition of a set of \texttt{antP} processes that all run in parallel, the evaporation process \texttt{evaporationP} and the process \texttt{cycleP} that decreases the number of cycles that are left to be executed by 1. Parallel execution of the ant processes is achieved by composing them using the \texttt{Multilel} constructor and combining their results using the \texttt{combinePathsP} process. \texttt{mkAntSystem} takes one parameter, \texttt{ants}, that specifies how many ants should be used in the ant system. All other information, including the number of cycles to be executed, the input graph and the pheromones are provided later in form of a configuration when the ant system is executed using the process interpreter \texttt{runProcess}.

As we can see, it is possible to describe an ant system without programming parallelisation and communication between processes explicitly. The developed process calculus is employed to model the structure and interplay of processes. Parallelisation and communication between processes is added automatically by the process interpreter \texttt{runProcess}.